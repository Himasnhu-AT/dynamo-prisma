// ! if prisma.schema exists, then appends after last model
// ? Partially implemented TODO: add secondary parser, to test for any possible bugs and recommend solutions, like automincement: true, type: int only.. so on..
// DONE TODO: if foreign key is false, type != anyModelType

// TODO: Add comment that this model is generated by schemaGenerator
// TOdo: create issue, if same model name defined in schema, then it should throw error in console, and not generate prisma schema

import * as fs from "fs";
import {
  createDataSource,
  createGenerator,
  createModel,
  createScalarField,
  createSchema,
  print,
} from "prisma-schema-dsl";
import { exec } from "child_process";
import {
  AUTO_INCREMENT,
  DataSourceProvider,
  DataSourceURLEnv,
  Enum,
  ScalarType,
  UUID,
  isDataSourceURLEnv,
} from "prisma-schema-dsl-types";
import { JsonChecks } from "./checks";

export interface Field {
  fieldName: string;
  type: string;
  description: string;
  maxLength: number | null;
  default?: string | null;
  autoincrement?: boolean;
  uuid?: boolean;
  nullable: boolean;
  unique: boolean;
  isId?: boolean;
  vectorEmbed?: boolean;
  embeddingAlgo?: string;
  isForeignKey?: boolean;
  isList?: boolean;
}

export interface Schema {
  schema: [{ schemaName: string; fields: Field[]; description: string }];
  dataSource?: {
    name: string;
    provider: DataSourceProvider;
    url: {
      url: string;
      fromEnv: DataSourceURLEnv;
      // fromEnv: DataSourceURLEnv;
    };
  };
  enum?: Enum[];
  generator?: {
    generatorName: string;
    provider: string;
    output: string;
    binaryTargets: string[];
  };
}

export function generatePrismaSchemaFromFile(filePath: string): void {
  console.warn("File path: ", filePath);
  readJsonFile(filePath)
    .then(async (jsonData: Schema) => {
      console.log("Applying Checks....");
      JsonChecks(jsonData);
      const models: any[] = createModels(jsonData.schema);
      console.log("Model generated");
      // console.log(models);
      // console.warn(
      //   "URL is ENV",
      //   isDataSourceURLEnv(jsonData.dataSource!.urlEnv)
      // );           // ! COMES OUT FALSE

      // const dbUrl = env("DATABASE_URL");
      // const DataSource = createDataSource(
      //   jsonData.dataSource?.name ? jsonData.dataSource!.name : "db",
      //   jsonData.dataSource!.provider || DataSourceProvider.PostgreSQL,
      //   dbUrl
      //   // jsonData.dataSource?.url
      //   //   ? jsonData.dataSource!.url.url
      //   //     ? jsonData.dataSource!.url.url
      //   //     : // : (env(`${jsonData.dataSource!.url.fromEnv}"`) as unknown as string)
      //   //       `${jsonData.dataSource!.url.fromEnv.name}`
      //   //   : "localhost:5432"
      // );
      // console.log("DataSource generated");
      // // console.log(DataSource);

      const DataSource: string = `datasource db {\n provider = "postgresql"\n url = env("DATABASE_URL")\n}`;

      var result: string;

      const Generator = createGenerator(
        jsonData.generator ? jsonData.generator!.generatorName : "client",
        jsonData.generator ? jsonData.generator!.provider : "prisma-client-js",
        jsonData.generator ? jsonData.generator!.output : undefined, // can be null | undefined | string( // ? Example Value: "node_modules/@prisma/client")
        jsonData.generator ? jsonData.generator!.binaryTargets : undefined // can be null | undefined | string[]
      );

      const Enum = jsonData.enum!;
      const schema = createSchema(models, Enum, undefined, [Generator]);
      const schemaString = await print(schema);
      result = DataSource + "\n" + schemaString;

      // fs.existsSync("./prisma/schema.prisma") // ? Check if prisma file exists, if yes, then append
      // console.log(result);
      console.warn("schema generated");
      // console.log(schema);

      fs.mkdirSync("./prisma", { recursive: true });
      fs.writeFile("./prisma/schema.prisma", result, (err) => {
        if (err) {
          console.error("Error writing Prisma schema:", err);
        } else {
          console.log("Prisma schema generated successfully!");
          // TODO: DONE RUN: npx prisma validate
          // exec("npx prisma validate", (error, stdout, stderr) => {
          //   if (error) {
          //     console.error("Error executing 'npx prisma validate':", error);
          //     return;
          //   }
          //   console.log("commands executed successfully", stdout);
          // });

          // TODO: DONE RUN: prisma migrate dev
          // exec("prisma migrate dev", (error, stdout, stderr) => {
          //   if (error) {
          //     console.error("Error executing 'prisma migrate dev':", error);
          //     return;
          //   }
          //   console.log("Output of 'prisma migrate dev':", stdout);
          // });
        }
      });
    })
    .catch((error) => {
      console.error("Error parsing JSON:", error);
    });
}

export function readJsonFile(filePath: string): Promise<Schema> {
  return new Promise((resolve, reject) => {
    fs.readFile(filePath, "utf8", (err, data) => {
      if (err) {
        console.error("Failed to read File. ERROR: ", err);
        reject(err);
        return;
      }

      try {
        const jsonData: Schema = JSON.parse(data);
        console.log("JSON Parsed");
        resolve(jsonData);
      } catch (error) {
        console.error("Failed to parse. ERROR: ", err);
        reject(error);
      }
    });
  });
}

export function createModels(schema: Schema["schema"]): any[] {
  const models: any[] = [];
  for (const schemaItem of schema) {
    const fields: any[] = createFields(schemaItem.fields);
    models.push(createModel(schemaItem.schemaName, fields));
  }
  return models;
}

// increment is breaking the code
// ! ERROR: Error parsing JSON: Error: Default must be a number or call expression to autoincrement()
// ? Log by console.war:
/*  String;
    Default
    Default
    Default
    Default
    Default
    Int 
*/
export function createFields(fields: Field[]): any[] {
  // console.error("Feilds: ", fields);
  const result: any[] = [];
  for (const fieldData of fields) {
    fieldData.isId && fieldData.autoincrement
      ? console.error("Cannot have String in autoincrement")
      : null;

    // TODO @db.Uuid if default is uuid, and isId is true
    result.push(
      createScalarField(
        fieldData.fieldName,
        // fieldData.type as ScalarType
        //
        //   : fieldData.isId && fieldData.uuid
        //   ? ScalarType.String
        //   :
        fieldData.type as ScalarType,
        fieldData.isList, //isList boolean | undefined
        !fieldData.nullable || false, //isRequired boolean | undefined
        fieldData.isId ? fieldData.isId : fieldData.unique || false,
        fieldData.isId || false,
        undefined, // isUpdatedAt
        fieldData.isId && fieldData.autoincrement
          ? { callee: AUTO_INCREMENT }
          : fieldData.isId && fieldData.uuid
          ? { callee: UUID }
          : fieldData.default, // default values SaclarFeildDefault | undefined
        undefined, // documentation string | undefined
        fieldData.isForeignKey, // isForeignKey boolean | undefined
        undefined // attributes in string | string[] | undefined
      )
    );

    if (fieldData.vectorEmbed) {
      result.push(
        createScalarField(
          `${fieldData.fieldName}Algorithm`,
          "String" as ScalarType,
          false,
          true,
          false,
          false,
          undefined,
          `"${fieldData.embeddingAlgo}"`,
          undefined,
          undefined,
          undefined
        ),

        createScalarField(
          `${fieldData.fieldName}Embedding`,
          `Unsupported("vector(${
            fieldData.embeddingAlgo!.length
          })")` as ScalarType,
          false,
          true,
          false,
          false,
          undefined,
          undefined,
          undefined,
          undefined,
          undefined
        )
      );
    }
  }
  // console.log("Results: ", result);
  return result;
}
